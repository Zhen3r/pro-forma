---
title: "Predicting rideshare demand in New York City"
author: "Zhenzhao Xu"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_float: true
editor_options: 
  markdown: 
    wrap: sentence
  chunk_output_type: inline
---

```{r}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	results=FALSE,
	fig.align="center",
	cache=T
)
```

```{r}
library(tidyverse)
library(tidycensus)
library(sf)
library(kableExtra)
library(patchwork)
library(ggplot2)
library(viridis)
library(gridExtra)
library(knitr)
library(lubridate)
library(riem)
library(osmdata)

library(hms)

library(caret)

library(stargazer)

options(scipen=999)
options(tigris_class = "sf")
options(tigris_use_cache = TRUE)
source("functions.r")

p5 = viridis::plasma(5)
p2 = p5[c(4,2)]

v = mapview::mapview

# NAD83(2011) / San Francisco CS13
crs = 7131
```

## 1. Introduction

Motivate the analysis – “What is the use case; why would someone want to replicate your analysis and why would they use this approach?”

Parking fee?
https://data.sfgov.org/Transportation/Meter-Rate-Schedules/fwjv-32uk

Parking time limits (from ? to ? / up to ? hours)
https://data.sfgov.org/Transportation/Parking-regulations-except-non-metered-color-curb-/hi6h-neyh


https://www.way.com/parking//37.7879938/-122.4074374/Union-Square/

## 2. Data

Meters data
```{r}
meter_trans = read.csv("./data/meter_trans_2021-09.csv")%>%
  mutate(
    interval60 = floor_date(ymd_hms(session_start_dt), unit = "hour"),
    # week = week(interval60),
    # dotw = wday(interval60, label=TRUE),
    parking_time = as.numeric(ymd_hms(session_end_dt)-ymd_hms(session_start_dt)))%>%
  filter(parking_time>0)

meters = st_read("./data/Parking Meters.geojson")%>%
  select(post_id, ms_space_num, on_offstreet_type, active_meter_flag, meter_type,
         street_id, street_seg_ctrln_id, longitude, latitude, geometry)%>%
  st_transform(crs)%>%
  mutate(
    street_seg_ctrln_id = street_seg_ctrln_id%>%as.numeric()%>%as.character(),
    ms_space_num = as.numeric(ms_space_num),
    ms_space_num = if_else(ms_space_num==0,1,ms_space_num)
  )

sf_neighborhood <-st_read("./data/SF Find Neighborhoods.geojson")%>%
  st_transform('EPSG:7131')
```

Creating Parking Time Panel
```{r eval=FALSE}
parking.time.panel =
  expand.grid(interval60 = unique(weather.Panel$interval60), 
              post_id = unique(meter_trans$post_id))%>%
  mutate(parking_time_in_60m = 0,
         index = row_number())
# meter_trans%>%write_csv("./processed_meter_trans.csv")
```

Processing Parking Time Panel
```{python eval=FALSE}
"""
The function below is used to union the parking time windows of each meter 
and split the time windows into its panel.

[Input]    meterTrans: pd.DataFrame
[Output] parkTimePanel: numpy.array[sympy.Interval[datetime.datetime, datetime.datetime]]
                        (each array element is a parking interval)
"""

for rowNumber in range(meterTrans.shape[0]):
    start_time_rounded = meterTrans.loc[rowNumber, "interval60"]
    start_time = meterTrans.loc[rowNumber, "session_start_dt"].timestamp()
    end_time = meterTrans.loc[rowNumber, "session_end_dt"].timestamp()
    post_id_row = meterTrans.loc[rowNumber, "post_id"]

    while start_time<end_time:
      # get the last minute of this hour
      this_end = min(end_time, start_time + 3600 - start_time%3600)
      this_interval = [start_time, this_end]
      # find the index of this hour and this meter in the meter panel
      index = meterPanel.loc[(post_id_row,start_time_rounded),"rownum"]
      # union the time window
      u = union(array[index], this_interval)
      parkTimePanel[index]=u
      # if parking time > 1hr, continue to the next hour
      start_time_rounded += onehour
      start_time = this_end
```

Loading Processed Parking Time Panel
```{r}
parking.time.panel = read.csv("./data/parking_spot_panel.csv")

parking.time.panel.sum = parking.time.panel%>%
  left_join(meters%>%st_drop_geometry()%>%
      select(street_seg_ctrln_id,post_id), by = "post_id")%>%
  group_by(street_seg_ctrln_id,interval60)%>%
  summarise(parking_time_in_60m = sum(parking_time_in_60m))
parking.time.panel.sum

# parking.time.panel.sum%>%
#   group_by(interval60)%>%
#   summarise(parking_time_in_60m = sum(parking_time_in_60m))%>%
#   ggplot()+
#     geom_col(aes(ymd_hms(interval60),parking_time_in_60m))

parking.time.panel.sum<-
  parking.time.panel.sum%>%
mutate(week = week(interval60),
       dotw = wday(interval60, label=TRUE))

parking.time.panel.sum<-
  parking.time.panel.sum%>%
  mutate(status = ifelse(week <= 37, "train", "test"))

sundays <- 
  mutate(parking.time.panel.sum,
         sunday = ifelse(dotw == "Sun" & hour(interval60) == 1,
                         interval60, 0)) %>%
  filter(sunday != 0)

sundays <-
  sundays%>%
  mutate(sunday = as.POSIXct(sunday))

parking.time.panel.sum%>%
  filter(interval60>= "2021-09-01 00:00:00" & interval60 <= "2021-09-30 23:59:59")%>%
  group_by(interval60, status)%>%
  summarise(parking_time_in_60m = sum(parking_time_in_60m))%>%
  ggplot(aes(ymd_hms(interval60),parking_time_in_60m, colour = status))+
    geom_line()+
  geom_vline(data = sundays, aes(xintercept = sunday))+
  scale_colour_manual(values = p2)+
  labs(title="Total Parking Time by week in SF: September 2021",
       x="Day", y="Total Parking Time") +
  plotTheme() + theme(panel.grid.major = element_blank())
  
# parking.time.panel.sum%>%
#   filter(interval60>= "2021-09-01 00:00:00" & interval60 <= "2021-09-30 23:59:59")%>%
#   filter(street_seg_ctrln_id == "1363000")%>%
#   ggplot(aes(ymd_hms(interval60),parking_time_in_60m, colour = "red"))+
#     geom_line()+
#    geom_vline(data = sundays, aes(xintercept = sunday))
  
```

Create parking census
```{r}
parking_census <- read.csv("data/On-Street_Parking_Census.csv")%>%
  select(CNN, PRKG_SPLY)
parking_census$CNN <- as.character(parking_census$CNN)

parking_seg_census <- meters%>%
  select(street_seg_ctrln_id, geometry)%>%
  distinct(street_seg_ctrln_id, .keep_all = T)

parking_seg_census <- parking_seg_census%>%
  left_join(parking_census, by = c("street_seg_ctrln_id"="CNN"))%>%
  drop_na(PRKG_SPLY)%>%
  rename(spots_num_census = PRKG_SPLY)

# off_parking_census <- read.csv("data/SFMTA_Managed_Off-street_Parking.csv")%>%
#   select(STREET_SEG_CTRLN_ID, CAPACITY)
```

City amenities data
```{r}
transit <- st_read("data/Muni Stops.geojson")%>%
  st_transform(crs)

park_public <- st_read("data/Recreation and Parks Properties.geojson")%>%
  st_transform(crs)%>%
  select(propertytype, geometry)%>%
  rename(type=propertytype)

park_private <- st_read("data/Privately Owned Public Open Spaces.geojson")%>%
  st_transform(crs)%>%
  select(type, geometry)

cultural_district <- st_read("data/Cultural Districts.geojson")%>%
  st_transform(crs)

st_c = st_coordinates
parking_seg_census <-
  parking_seg_census %>%
  mutate(
    transit.nn =
      nn_function(st_c(parking_seg_census), st_c(transit),1),
    park_public.nn =
      nn_function(st_c(parking_seg_census), st_c(st_centroid(park_public)),1),
    cultural_district.nn =
      nn_function(st_c(parking_seg_census), st_c(st_centroid(cultural_district)),1))
```

OSM data
```{r}
## OSM Data

sf_boundary <- st_read("data/Bay Area Counties.geojson")%>%
  filter(county == "San Francisco")%>%
  st_transform(crs)%>%
  select(geometry)

q0 <- osmdata::opq(bbox = c(-122.3505,37.7025,-122.5171,37.8364)) 

restaurant <- add_osm_feature(opq = q0, key = 'amenity', value = "restaurant") %>%
  osmdata_sf(.)
restaurant.sf <- st_geometry(restaurant$osm_points) %>%
  st_transform(4326) %>%
  st_sf() %>%
  cbind(., restaurant$osm_points$amenity) %>%
  rename(NAME = restaurant.osm_points.amenity)%>%
  st_transform(crs)%>%
  st_intersection(sf_boundary)%>%
  dplyr::select(geometry)%>%
  distinct()

theatre <- add_osm_feature(opq = q0, key = 'amenity', value = "theatre") %>%
  osmdata_sf(.)
theatre.sf <- st_geometry(theatre$osm_points) %>%
  st_transform(4326) %>%
  st_sf() %>%
  cbind(., theatre$osm_points$amenity) %>%
  rename(NAME = theatre.osm_points.amenity)%>%
  st_transform('EPSG:7131')%>%
  st_intersection(sf_boundary)%>%
  dplyr::select(geometry)%>%
  distinct()

cafe <- add_osm_feature(opq = q0, key = 'amenity', value = "cafe") %>%
  osmdata_sf(.)
cafe.sf <- st_geometry(cafe$osm_points) %>%
  st_transform(4326) %>%
  st_sf() %>%
  cbind(., cafe$osm_points$amenity) %>%
  rename(NAME = cafe.osm_points.amenity)%>%
  st_transform('EPSG:7131')%>%
  st_intersection(sf_boundary)%>%
  dplyr::select(geometry)%>%
  distinct()

clothes <- add_osm_feature(opq = q0, key = 'shop', value = "clothes") %>%
  osmdata_sf(.)
clothes.sf <- st_geometry(clothes$osm_points) %>%
  st_transform(4326) %>%
  st_sf() %>%
  cbind(., clothes$osm_points$shop) %>%
  rename(NAME = clothes.osm_points.shop)%>%
  st_transform('EPSG:7131')%>%
  st_intersection(sf_boundary)%>%
  dplyr::select(geometry)%>%
  distinct()

parking_seg_census <-
  parking_seg_census %>%
  mutate(
    restaurant.nn =
      nn_function(st_c(parking_seg_census), st_c(restaurant.sf),3),
    cafe.nn =
      nn_function(st_c(parking_seg_census), st_c(cafe.sf),3),
    theatre.nn =
      nn_function(st_c(parking_seg_census), st_c(theatre.sf),3),
    clothes.nn =
      nn_function(st_c(parking_seg_census), st_c(clothes.sf),3))

park.engineer = parking.time.panel.sum%>%
  left_join(
    parking_seg_census%>%
      # log all the nn vars
      mutate_at(ends_with(".nn")%>%vars()%>%all_of(),log),
    by="street_seg_ctrln_id")

```

adding Time Lag + time dummy
```{r}
park.engineer = park.engineer%>%
  rename(street.id = street_seg_ctrln_id)%>%
  group_by(street.id) %>% 
  mutate(lagHour = dplyr::lag(parking_time_in_60m,1),
         lag2Hours = dplyr::lag(parking_time_in_60m,2),
         lag3Hours = dplyr::lag(parking_time_in_60m,3),
         lag4Hours = dplyr::lag(parking_time_in_60m,4),
         lag12Hours = dplyr::lag(parking_time_in_60m,12),
         lag1day = dplyr::lag(parking_time_in_60m,24),
         lagWeek = dplyr::lag(parking_time_in_60m,24*7),
         week = interval60%>%week,
         weekday = interval60%>%wday(T),
         is.weekend = interval60%>%wday(week_start=1)>=6,
         hour = interval60%>%hour()) %>% 
 ungroup()
```



Weather
```{r}
weather.SF <- 
  riem_measures(station = "SFO", date_start = "2021-09-01", date_end = "2021-10-01")

weather.Panel <-  
  weather.SF %>%
  mutate_if(is.character, list(~replace(as.character(.), is.na(.), "0"))) %>% 
  replace(is.na(.), 0) %>%
  mutate(interval60 = ymd_h(substr(valid, 1, 13))) %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label=TRUE)) %>%
  group_by(interval60) %>%
  summarize(Temperature = max(tmpf),
            Percipitation = sum(p01i),
            Wind_Speed = max(sknt)) %>%
  mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

park.engineer = park.engineer%>%
  mutate(interval60 = ymd_hms(interval60))%>%
  left_join(weather.Panel,by="interval60")%>%
  drop_na(Temperature) # to remove data on OCT.01
```

## 3. exploratory analysis  using maps and plots

```{r}
park.engineer %>% 
  select(parking_time_in_60m) %>% 
  ggplot(aes(parking_time_in_60m))+
    geom_histogram()

```





Meter Inconsistency Visualization
```{r}
meter.notfound = setdiff(unique(meter_trans$post_id),unique(meters$post_id))%>%length()
meter.inactive = setdiff(unique(meters$post_id),unique(meter_trans$post_id))%>%length()
meter.intersection = intersect(unique(meters$post_id),unique(meter_trans$post_id))%>%length()
data.frame("meter.inactive"=meter.inactive,
           "meter.notfound"=meter.notfound,
           "meter.intersection"=meter.intersection)%>%
  gather()%>%
ggplot(aes(key,value))+
  geom_col()
```


```{r}
plotData.lag <-
  as.data.frame(park.engineer)%>%
  dplyr::select(starts_with("lag"), parking_time_in_60m) %>%
  gather(Variable, Value, -parking_time_in_60m) %>%
  mutate(Variable = fct_relevel(Variable, "lagHour","lag2Hours","lag3Hours",
                                "lag4Hours","lag12Hours","lag1day"))
correlation.lag <-
  group_by(plotData.lag, Variable) %>%
  summarize(correlation = round(cor(Value, parking_time_in_60m, use = "complete.obs"), 2)) %>%
  kable(caption = "Parking Time in One Hour") %>%
  kable_styling("striped", full_width = F)

correlation.lag
```

```{r}
int.ampeak <- interval(as_hms("07:00:00"),as_hms("10:00:00"))
int.pmpeak <- interval(as_hms("15:00:00"),as_hms("18:00:00"))
int.midday <- interval(as_hms("10:00:00"),as_hms("15:00:00"))
int.night <- interval(as_hms("18:00:00"),as_hms("23:00:00"))
int.overnight <- interval(as_hms("00:00:00"),as_hms("07:00:00"))

parking.time.panel.sum <-parking.time.panel.sum%>%
  mutate(period = case_when(ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.ampeak ~ "AM",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.pmpeak ~ "PM",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.midday ~ "Mid_Day",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.night ~ "Night",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.overnight ~ "Overnight"))


parking.time.panel.sum %>%
  group_by(interval60, street_seg_ctrln_id, period) %>%
  summarize(mean_time = mean(parking_time_in_60m))%>%
  ggplot()+
  geom_histogram(aes(mean_time), binwidth = 10000)+
  labs(title="Mean Number of Hourly Trips Per Station",
       subtitle="Philadelphia, October 8th - November 11st, 2019",
       x="Mean Parking Time", 
       y="Frequency")+
  facet_wrap(~period)+
  plotTheme()

```

```{r fig.height=5, fig.width=8}
park.engineer <-park.engineer%>%
  mutate(period = case_when(ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.ampeak ~ "AM",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.pmpeak ~ "PM",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.midday ~ "Mid_Day",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.night ~ "Night",
                            ymd_hms(paste0('1970-01-01',str_sub(interval60, 12)))%within% int.overnight ~ "Overnight"))

park.engineer.map = park.engineer %>%
  group_by(street.id, period) %>%
  summarize(mean_time = mean(parking_time_in_60m))%>%
  ungroup()%>%
  left_join(meters.bySegId,by = c("street.id"="street_seg_ctrln_id"))%>%
  mutate(across(period, factor, levels=c("Overnight","AM","Mid_Day","PM","Night"))) %>%
  st_sf()
map.lables = qBr(park.engineer.map,"mean_time")

park.engineer.map%>%
  filter(period=="Mid_Day")%>%#sample_n(10000)%>%
ggplot()+
  geom_sf(data = sf_neighborhood, fill="#cccccc", color="#999999")+
  geom_sf(aes(color=mean_time,size=mean_time,alpha=mean_time),
           stroke = .2, shape = 16)+
  viridis::scale_color_viridis(option = "C")+
  scale_size_continuous(range = c(0.2,4))+
  scale_alpha_continuous(range = c(0.5,1))+
  labs(title="Mean Parking Time of Street Segments by Time",
       subtitle = "San Francisco, 2021.9")+
  mapTheme()

park.engineer.map%>%
  filter(mean_time>0)%>%
  sample_n(10000)%>%
ggplot()+
  geom_sf(data = sf_neighborhood, fill="#cccccc", color="#999999")+
  geom_sf(data=park.engineer.map%>%filter(mean_time==0),
          aes(color=rev(q5(mean_time)),size=0.2,alpha=0.1),
          stroke = .4, shape = 16)+
  geom_sf(aes(color=rev(q5(mean_time)),size=mean_time,alpha=mean_time),
          stroke = .6, shape = 16)+
  scale_color_manual(values=p5,labels=qBr(park.engineer.map,"mean_time"))+
  scale_size_continuous(range = c(0.4,2))+
  scale_alpha_continuous(range = c(0.3,0.6))+
  facet_wrap(~period,nrow=2)+
  labs(title="Mean Parking Time of Street Segments by Time",
       subtitle = "San Francisco, 2021.9")+
  mapTheme()
```

nn
```{r fig.height=3, fig.width=8}
parking_seg_census%>%
  pivot_longer(cols=ends_with(".nn"),names_to="name1",values_to="value_raw")%>%
  mutate(value_logged = log(value_raw))%>%
  pivot_longer(cols=starts_with("value"),names_to="if_log",values_to="name_log")%>%
  ggplot()+
    geom_histogram(aes(name_log),bins=50)+
    facet_wrap(if_log~name1,scales = "free",nrow=2)+
    plotTheme()
```


Corr
```{r}

```

### 3.? What is the spatial or space/time process?
```{r}

```




## 4. Describe your modeling approach and show how you arrived at your final model.

```{r}
park.Train = filter(park.engineer, week <= 37) # 35~37
park.Test = filter(park.engineer, week > 37 & week < 40) # 38~39

formula1 = parking_time_in_60m ~ spots_num_census + Temperature+Wind_Speed+weekday+hour

formula2 = parking_time_in_60m ~  spots_num_census + Temperature+Wind_Speed +transit.nn +park_public.nn+park_public.nn+cultural_district.nn+restaurant.nn+cafe.nn+theatre.nn+clothes.nn+weekday+hour

formula3 = parking_time_in_60m ~ spots_num_census + lagHour + lag2Hours+lag3Hours+lag4Hours+lag1day+Temperature+Wind_Speed+weekday+hour

formula4 = parking_time_in_60m ~  spots_num_census + lagHour + lag2Hours+lag3Hours+lag4Hours+lag12Hours+lag1day+weekday+hour+transit.nn +park_public.nn+park_public.nn+cultural_district.nn+restaurant.nn+cafe.nn+theatre.nn+clothes.nn+Temperature+Wind_Speed

reg1 <- lm(formula1, data=park.Train)
reg2 <- lm(formula2, data=park.Train)
reg3 <- lm(formula3, data=park.Train)
reg4 <- lm(formula4, data=park.Train)

reg.pos = glm(formula4, data=park.Train,family = "poisson",na.action = na.omit)
# cost=function(x,y) mean(abs(x-y),na.rm=T)
# reg.pos.cv = boot::cv.glm(park.Train,reg.pos,K=2,cost = cost)

# summary(reg1)
# summary(reg2)
# summary(reg3)
# summary(reg4)
# summary(reg.pos)

stargazer(reg1, reg2, reg3, reg4, type ="text", font.size = "small", single.row = TRUE)
stargazer(reg4, type ="text", font.size = "small", single.row = TRUE)

# jtools::plot_summs(reg.pos)
```

```{r}
model_pred <- function(dat, fit){
   pred <- predict(fit, newdata = dat)}

park.Test.weekNest <- 
  as.data.frame(park.Test) %>%
  nest(-week) 

week_predictions <- 
  park.Test.weekNest %>% 
    mutate(Weather_Time_model = map(.x = data, fit = reg1, .f = model_pred),
           Space_Time_model = map(.x = data, fit = reg2, .f = model_pred),
           Lag_Time_model = map(.x = data, fit = reg3, .f = model_pred),
           Time_Space_Lag_Weather_model = map(.x = data, fit = reg4, .f = model_pred),
           Poission_model = map(.x = data, fit = reg.pos, .f = model_pred))

mean.na = function(x) {mean(x,na.rm=T)}
sd.na = function(x) {sd(x,na.rm=T)}

week_predictions <- week_predictions %>%  
    gather(Regression, Prediction, -data, -week) %>% 
    mutate(Observed = map(data, pull, parking_time_in_60m),
           Absolute_Error = map2(Observed, Prediction,  ~ abs(.x - .y)),
           MAE = map_dbl(Absolute_Error, mean.na),
           sd_AE = map_dbl(Absolute_Error, sd.na))

week_predictions %>%
  dplyr::select(week, Regression, MAE) %>%
  gather(Variable, MAE, -Regression, -week) %>%
  mutate(
    across(Regression,factor,levels=c("Weather_Time_model","Space_Time_model","Poission_model",
                                    "Lag_Time_model","Time_Space_Lag_Weather_model"))
  )%>%
  ggplot(aes(week%>%as.factor(), MAE)) + 
    geom_bar(aes(fill = Regression), position = "dodge", stat="identity") +
    scale_fill_manual(values = plasma(8)[2:6]) +
    labs(title = "Mean Absolute Errors by model specification and week",x="week") +
  plotTheme()

```


## 5. Validate your model with cross-validation and describe how your predictions are useful (accuracy vs. generalizability).
```{r}
# cross-validation
fitControl <- caret::trainControl(method = "cv", number = 50,savePredictions=T)
set.seed(1)
reg.cv = caret::train(formula4, data = park.engineer, 
     method = "lm", trControl = fitControl, na.action = na.pass)
summary(reg.cv)

reg.cv <-reg.cv%>%
  dplyr::select(cvID = street.id, parking_time_in_60m, Prediction)

reg.summary <- mutate(reg.cv, Error = Prediction - parking_time_in_60m,
                      Regression = "random k-fold cross validation on the 5 week panel")

error_by_reg_and_fold <- 
  reg.summary %>%
  group_by(Regression, cvID) %>% 
  summarize(Mean_Error = mean(Prediction - Trip_Count, na.rm = T),
            MAE = mean(abs(Mean_Error), na.rm = T),
            SD_MAE = mean(abs(Mean_Error), na.rm = T)) %>%
  ungroup()
error_by_reg_and_fold.long <-
  error_by_reg_and_fold%>%
  gather(Vriable, Value, -cvID, -Regression)%>%
  unnest()
```


```{r fig.height=4, fig.width=6}
week_predictions %>% 
  mutate(interval60 = map(data, pull, interval60)) %>%
  dplyr::select(interval60, Observed, Prediction, Regression) %>%
  unnest() %>%
  gather(Variable, Value, -Regression, -interval60) %>%
    group_by(Regression, Variable, interval60) %>%
    summarize(Value = mean(Value,na.rm=T)) %>%
    mutate(across(Regression, factor, 
                  levels=c("Weather_Time_model","Space_Time_model",
                           "Lag_Time_model","Time_Space_Lag_Weather_model"))) %>%
    ggplot(aes(interval60, Value, colour=Variable)) + 
      geom_line(size = .8) + 
      facet_wrap(~Regression, ncol=1) +
      scale_colour_manual(values = p2) +
      labs(title = "Mean Predicted/Observed bike share by hourly interval", 
           x = "Hour", y= "Bikeshare Trips") +
      plotTheme()
```

```{r}
error.byWeek <-
  filter(week_predictions, Regression == "Time_Space_Lag_Weather_model") %>% 
  unnest() %>% st_sf() %>%
  dplyr::select(street.id, Absolute_Error, week, geometry) %>%
  gather(Variable, Value, -street.id, -week, -geometry) %>%
  group_by(Variable, street.id, week) %>%
  summarize(MAE = mean(Value), na.rm=TRUE)%>%
  ggplot()+
  geom_sf(aes(color=MAE),
          fill = "transparent", alpha=0.6, size=0.2)+
  geom_sf(data = sf_neighborhood)+
  facet_grid(~week)
```


## 6. Provide additional maps and data visualizations to show that your model is useful.
```{r}

mae_map = filter(week_predictions, Regression == "Time_Space_Lag_Weather_model") %>% 
  unnest()%>%st_sf() %>%
  dplyr::select(street.id, Absolute_Error, geometry) %>%
  group_by(street.id) %>%
  summarize(MAE = mean(Absolute_Error, na.rm=TRUE))

# mae_map_nbh = mae_map%>%
#   st_join(sf_neighborhood)%>%
#   group_by(name)%>%
#   st_drop_geometry()%>%
#   right_join(sf_neighborhood)%>%
#   st_sf()
  
ggplot(mae_map%>%drop_na(MAE)%>%st_sf())+
  geom_sf(data = sf_neighborhood, fill="#cccccc", color="#999999")+
  geom_sf(aes(color=q5(MAE)),stroke=0.5,size=0.5)+
  scale_color_manual(values=p5,labels=qBr(mae_map_nbh,"MAE"),
                     name="MAE(Quantile)")+
  labs(title="Spatial Distribution o")+
  mapTheme()

parking_seg_census$spots_num_census%>%
  mean()

```

```{r}
reg.summary <-reg.cv$pred%>%
  select(foldNum = Resample,pred,obs)%>%
  mutate(AE = abs(pred-obs),
         APE = abs(pred-obs)/obs)%>%
  group_by(foldNum)%>%
  summarise(MAE = mean(AE,na.rm=T),
            SD_MAE = sd(AE,na.rm=T))

reg.summary %>%
  pivot_longer(-foldNum)%>%
  ggplot(aes(value))+
  geom_histogram(colour="black", fill = p5[4])+
  facet_wrap(~name,scale='free')+
  labs(title="Distribution of MAE",
       subtitle = "50-fold cross-validation")+
  plotTheme()
  

```



adding Parking fee
```{r}
fee = st_read("./data/rate.geojson")%>%st_transform(crs)
fee.geom = fee%>%
  group_by(old)%>%
  summarise(geometry2=st_union(geometry)) %>% 
  mutate(geometry2=st_centroid(geometry2)) %>%
  filter(!st_is_empty(.))
  
street.geom = read.csv("data/On-Street_Parking_Census.csv")%>%
  st_as_sf(wkt="shape",crs=4326)%>%
  st_transform(crs) %>% 
  select(street.id = CNN)%>%
  mutate(index = row_number())

nn.result = nngeo::st_nn(fee.geom$geometry2, street.geom$shape,k=1,returnDist=T)

fee.geom = fee.geom%>%mutate(
  nn.index = nn.result$nn%>%as.numeric(),
  nn.distance = nn.result$dist%>%as.numeric(),
) %>% 
  as.data.frame() %>% 
  left_join(street.geom,by=c("nn.index"="index")) %>% 
  st_sf()%>%
  filter(nn.distance<100)

fee.geom$street.id.x%>%unique()%>%length()
fee.geom%>%nrow()
fee.results = fee.geom%>%
  st_drop_geometry() %>% 
  group_by(street.id.x) %>% 
  summarise(old=first(old)) %>% 
  right_join(fee,by="old")%>% 
  select(
    -streets, -old, -STREET_NAME, -new,
    street.id = street.id.x
  )

fee.results 
```

## 7. Discussion

### 7.1 Talk about how your analysis meets the use case you set out to address.




### 7.2 What could you do to make the analysis better?



